import streamlit as st
import os
import zipfile
import tempfile
from pathlib import Path
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain_classic.chains import RetrievalQA
import requests
import groq

# ================= CONFIGURACI√ìN =================
GROQ_API_KEY = st.secrets.get("GROQ_API_KEY")
ZIP_URL = "https://github.com/alkhimiya/mindgeekclinicdeployment/raw/refs/heads/main/mindgeekclinic_db.zip"

# ================= DIAGN√ìSTICO DE MODELOS =================
def detectar_modelos_disponibles():
    """Detecta autom√°ticamente qu√© modelos est√°n disponibles."""
    try:
        client = groq.Groq(api_key=GROQ_API_KEY)
        modelos = client.models.list()
        
        modelos_disponibles = []
        for modelo in modelos.data[:10]:  # Primeros 10 modelos
            modelos_disponibles.append(modelo.id)
        
        return modelos_disponibles
    except Exception as e:
        return []

# ================= SISTEMA PRINCIPAL =================
@st.cache_resource
def cargar_sistema_completo():
    """Descarga la base y carga el sistema RAG."""
    
    if not GROQ_API_KEY:
        st.error("‚ùå ERROR: Configura GROQ_API_KEY en Streamlit Cloud Secrets.")
        st.info("Settings > Secrets > A√±ade: GROQ_API_KEY = 'tu_clave_groq'")
        return None
    
    with st.spinner("üöÄ Iniciando MINDGEEKCLINIC..."):
        try:
            # ===== PASO 1: DETECTAR MODELOS DISPONIBLES =====
            st.info("üîç Detectando modelos disponibles en tu cuenta...")
            modelos = detectar_modelos_disponibles()
            
            if not modelos:
                st.error("‚ùå No se pudieron detectar modelos. Verifica tu API Key.")
                return None
            
            st.success(f"‚úÖ {len(modelos)} modelos detectados")
            
            # Mostrar modelos disponibles
            with st.expander("üìã Modelos disponibles en tu cuenta"):
                for i, modelo in enumerate(modelos, 1):
                    st.write(f"{i}. `{modelo}`")
            
            # ===== PASO 2: BUSCAR MODELO QUE FUNCIONE =====
            modelos_a_probar = [
                "llama-3.3-70b-versatile",  # M√°s probable
                "llama-3.1-70b-versatile",
                "llama-3.2-90b-vision-preview",
                "llama-4-scout",
                "mixtral-8x7b-32768",
                "gemma2-9b-it",
                "llama-3.2-1b-preview",
            ]
            
            # Filtrar solo los que est√°n en los disponibles
            modelos_validos = []
            for modelo in modelos_a_probar:
                for disponible in modelos:
                    if modelo in disponible or disponible in modelo:
                        modelos_validos.append(disponible)
            
            if not modelos_validos:
                st.error("‚ùå No se encontr√≥ ning√∫n modelo compatible.")
                st.info("""
                **Instrucciones manuales:**
                1. Ve a: https://console.groq.com/playground
                2. Mira qu√© modelos ves en el dropdown
                3. Usa ese nombre EXACTO en el c√≥digo
                """)
                return None
            
            st.info(f"üîå Probando {len(modelos_validos)} modelos...")
            
            # ===== PASO 3: DESCARGAR BASE =====
            st.info("üì• Descargando base de conocimiento...")
            response = requests.get(ZIP_URL, stream=True, timeout=60)
            
            if response.status_code != 200:
                st.error(f"‚ùå Error {response.status_code} al descargar.")
                return None
            
            temp_dir = tempfile.mkdtemp()
            zip_path = os.path.join(temp_dir, "database.zip")
            extract_path = os.path.join(temp_dir, "mindgeekclinic_db")
            
            with open(zip_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            st.info("üóúÔ∏è Descomprimiendo...")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_path)
            
            archivos = [f for f in Path(extract_path).rglob('*') if f.is_file()]
            if len(archivos) == 0:
                st.error("‚ùå El ZIP est√° vac√≠o.")
                return None
            
            st.success(f"‚úÖ Base cargada: {len(archivos)} archivos.")
            
            # ===== PASO 4: CARGAR EMBEDDINGS =====
            st.info("üß† Inicializando motor de b√∫squeda...")
            embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
            vector_store = Chroma(persist_directory=extract_path, embedding_function=embeddings)
            
            # ===== PASO 5: PROBAR MODELOS =====
            llm = None
            modelo_usado = None
            
            for modelo in modelos_validos:
                try:
                    st.write(f"  ‚Ä¢ Probando: `{modelo}`...")
                    llm = ChatGroq(
                        groq_api_key=GROQ_API_KEY,
                        model_name=modelo,
                        temperature=0.3,
                        max_tokens=2000
                    )
                    # Test r√°pido
                    test = llm.invoke("Hola")
                    modelo_usado = modelo
                    st.success(f"‚úÖ Modelo funcionando: `{modelo}`")
                    break
                except Exception as e:
                    if "404" in str(e):
                        continue
                    else:
                        st.warning(f"  ‚úó {modelo}: {str(e)[:50]}")
            
            if not llm:
                st.error("‚ùå Ning√∫n modelo funcion√≥.")
                return None
            
            # ===== PASO 6: CREAR SISTEMA RAG =====
            qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=vector_store.as_retriever(search_kwargs={"k": 6}),
                return_source_documents=True
            )
            
            st.success(f"üéØ ¬°SISTEMA ACTIVO! (Modelo: {modelo_usado})")
            return qa_chain
            
        except Exception as e:
            st.error(f"‚ùå Error: {str(e)[:150]}")
            return None

# ================= INTERFAZ =================
st.set_page_config(
    page_title="MINDGEEKCLINIC - Diagn√≥stico",
    page_icon="üß†",
    layout="wide"
)

st.title("üß† MINDGEEKCLINIC")
st.markdown("**Sistema con Diagn√≥stico Autom√°tico de Modelos**")
st.markdown("---")

# BARRA LATERAL
with st.sidebar:
    st.markdown("### ‚öôÔ∏è Configuraci√≥n")
    
    # Instrucciones
    with st.expander("üìã C√≥mo ver modelos manualmente"):
        st.markdown("""
        1. **Ve a:** [console.groq.com/playground](https://console.groq.com/playground)
        2. **Haz clic** en el dropdown de modelos
        3. **Copia** el nombre EXACTO
        4. **√ösalo** en el c√≥digo
        """)
    
    if st.button("üîÑ Reiniciar Sistema", use_container_width=True):
        st.cache_resource.clear()
        st.rerun()
    
    st.markdown("---")
    st.caption("üîç Diagn√≥stico autom√°tico activado")

# CARGAR SISTEMA
sistema = cargar_sistema_completo()

# Resto del c√≥digo de chat igual...
